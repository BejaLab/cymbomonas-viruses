
from pandas import read_csv, isnull
from os import path
from hashlib import sha256
from Bio import SeqIO
from collections import defaultdict

# Defaults
segment_flanks = 50000
models = { "MCP_PLV": "Blosum62+F+R5", "MCP_NCLDV": "LG+F+R9" }

PLV_scores = { 'PLV2': 100, 'PLVA': 175, 'PLVB': 175 }
PLVs = list(PLV_scores.keys())
PLV_outgroups = [ 'TVS', 'S.punctatus', 'Gezel' ]

NCLDVs = [ 'AG_03', 'Prasinoviridae', 'Chlorovirus' ]

# Get variables from globs
genomes,       = glob_wildcards("genomes/{genome}.fna")
clusters,      = glob_wildcards("clusters/{cluster}.fasta")
algae,         = glob_wildcards("algae/{genome}.fna")
hmms,          = glob_wildcards("hmm/{hmm}.hmm")
mcp_hmms,      = glob_wildcards("hmm/MCP/{hmm}.hmm")
hmm_algae,     = glob_wildcards("hmm_algae/{hmm}.hmm")
capsid_proteins = defaultdict(list)
# Get variables from files
with open("metadata/capsid_proteins.txt") as fh:
    for line in fh:
        hmm, CP = line.rstrip().split()
        capsid_proteins[CP].append(hmm)

algae = {}
with open("metadata/algae.txt") as fh:
   for line in fh:
       acc, organism = line.rstrip().split('\t')
       algae[acc] = organism

NCLDV_markers = {}
with open("metadata/NCLDV_markers.txt") as fh:
    for line in fh:
        hmm, score = line.strip().split()
        NCLDV_markers[hmm] = score

viruses_file  = 'metadata/viruses.tsv'

evalues = { "MCP_PLV": 1e-8, "MCP_NCLDV": 1e-8 }

viruses = {}
virus_clades = defaultdict(list)
data = read_csv(viruses_file, sep = '\t')
for i, row in data.iterrows():
    if isnull(row['fragment']):
        if row['exclude'] != 'y':
            short = row['short']
            clade = row['clade']
            viruses[short] = row.to_dict()
            virus_clades[clade].append(short)
virus_names = list(viruses.keys())

clades = set()
with open('metadata/curated/MCPs.faa') as fd:
    fasta = SeqIO.parse(fd, 'fasta')
    for record in fasta:
        subclade = record.id.partition('@')[2]
        clade = subclade.partition('-')[0]
        clades.add(clade)

# Include dependent snakefiles
# include: "Promoters.snakefile"
include: "Get_viruses.snakefile"
include: "Locate_viruses.snakefile"
# include: "Segments_extract.snakefile"
include: "Segments_search.snakefile"
# include: "Phylogeny_with_algae.snakefile"
# include: "Vcontact.snakefile"
include: "Remote_homology.snakefile"
include: "Phylogeny_NCLDVs.snakefile"
include: "Phylogeny_PLVs.snakefile"
include: "Algae.snakefile"

class bcolors:
    HEADER = '\033[95m'
    OKBLUE = '\033[94m'
    OKCYAN = '\033[96m'
    OKGREEN = '\033[92m'
    WARNING = '\033[93m'
    FAIL = '\033[91m'
    ENDC = '\033[0m'
    BOLD = '\033[1m'
    UNDERLINE = '\033[4m'

exposed_rules = [ 'viruses_ncbi_fna', 'mcp_algae', 'promoters', 'remote_homology', 'extract_segments', 'search_segments', 'vcontact', 'phylogeny' ]

rule default:
    run:
        print(f"{bcolors.FAIL}No task selected - choose one of %s\nKeep in mind that all rules except search_segments are dependent on extract_segments{bcolors.ENDC}\n" % ', '.join(exposed_rules))

rule makeblastdb_prot:
    input:
        "{fasta}"
    output:
        "{fasta}.pdb"
    conda:
        "envs/tools.yaml"
    shell:
        "makeblastdb -in {input} -dbtype prot"

rule faidx:
    input:
        "{fasta}"
    output:
        "{fasta}.fai"
    conda:
        "envs/tools.yaml"
    shell:
        "seqkit faidx {input}"

rule faidx_f:
    input:
        "{fasta}"
    output:
        "{fasta}.seqkit.fai"
    conda:
        "envs/tools.yaml"
    shell:
        "seqkit faidx -f {input}"

rule mad:
    input:
        "{treefile}"
    output:
        "{treefile}.rooted"
    shell:
        "mad {input}"

rule segments_genemarks:
    input:
        "{prefix}.fna"
    output:
        "{prefix}.genemarks.gff"
    shadow:
        "minimal"
    shell:
        """
        gmsn.pl --format GFF3 --virus --output tmp.gff {input}
        awk -F'\\t' '$2{{sub(/ .*/,"",$1)}}1' OFS='\\t' tmp.gff > {output}
        """

rule segments_prodigal:
    input:
        "{prefix}.fna"
    output:
        "{prefix}.prodigal.gff"
    shadow:
        "minimal"
    conda:
        "envs/prodigal.yaml"
    shell:
        "prodigal -i {input} -m -g 1 -p meta -f gff > {output}"

rule segments_genemarks_cat:
    input:
        "{prefix}.genemarks.gff",
        "{prefix}.prodigal.gff"
    output:
        "{prefix}.combined.gtf"
    conda:
        "envs/tools.yaml"
    shadow:
        "shallow"
    shell:
        """
        gffcompare -p NAME_PREFIX -CTo tmp {input}
        awk -v p=NAME_PREFIX -F'\\t' '{{sub(p,$1,$9)}}1' OFS='\\t' tmp.combined.gtf > {output}
        """

rule segments_gffread:
    input:
        gtf = "{prefix}.combined.gtf",
        fna = "{prefix}.fna",
        fai = "{prefix}.fna.fai"
    output:
        gff = "{prefix}.combined.gff",
        faa = "{prefix}.combined.faa"
    conda:
        "envs/tools.yaml"
    shell:
        "gffread -g {input.fna} -w - -o {output.gff} {input.gtf} | seqkit translate --trim -o {output.faa}"

rule makeblastdb:
    input:
        "{prefix}.fna"
    output:
        "{prefix}.fna.ndb"
    conda:
        "envs/tools.yaml"
    shell:
        "makeblastdb -in {input} -dbtype nucl"

rule merge_custom_hmms:
    input:
        expand("hmm/{hmm}.hmm", hmm = hmms)
    output:
        "analysis/hmm/custom.hmmdb"
    shell:
        "cat {input} > {output}"

rule hmmpress:
    input:
        "{prefix}.hmmdb"
    output:
        expand("{{prefix}}.hmmdb.{ext}", ext = [ "h3m", "h3i", "h3f", "h3p" ])
    conda:
        "envs/tools.yaml"
    shell:
        "hmmpress {input}"

rule custom_hmmscan:
    input:
        fasta = "{prefix}.faa",
        hmm = "analysis/hmm/custom.hmmdb",
        h3m = "analysis/hmm/custom.hmmdb.h3m"
    output:
        tblout = "{prefix}.custom.tblout",
        domtblout = "{prefix}.custom.domtblout"
    threads:
        4
    conda:
        "envs/tools.yaml"
    shell:
        "hmmscan --max --cpu {threads} -o /dev/null --tblout {output.tblout} --domtblout {output.domtblout} {input.hmm} {input.fasta}"

rule vogdb_hmmsearch:
    input:
        fasta = "{prefix}.faa",
        hmm = "databases/vogdb/output/vog.hmmdb"
    output:
        tblout = "{prefix}.vogdb.tblout",
        domtblout = "{prefix}.vogdb.domtblout"
    threads:
        4
    conda:
        "envs/tools.yaml"
    shell:
        "hmmscan --cpu {threads} -o /dev/null --tblout {output.tblout} --domtblout {output.domtblout} {input.hmm} {input.fasta}"

rule outfmt6_to_bed:
    input:
        "{prefix}.outfmt6"
    output:
        "{prefix}.outfmt6.bed"
    shell:
        "awk -vf=+ -vr=- -vd=. '{{n=$2;b=$9;e=$10;s=f}}b>e{{s=r;b=$10;e=$9}}{{print n,b-1,e,d,d,s}}' OFS=\\\\t {input} > {output}"

rule touch_blank:
    output:
        "analysis/blank.txt"
    shell:
        "touch {output}"
